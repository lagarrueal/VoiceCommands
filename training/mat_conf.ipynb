{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 09:22:05.927193: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-10 09:22:05.927729: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-10 09:22:05.927794: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Student-laptop): /proc/driver/nvidia/version does not exist\n",
      "2023-02-10 09:22:05.928967: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('../models/model_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_audio(audio_binary):\n",
    "    # Decode WAV-encoded audio files to `float32` tensors, \n",
    "    # normalized to the [-1.0, 1.0] range. Return `float32` audio and a sample rate.\n",
    "    try :\n",
    "        audio, _ = tf.audio.decode_wav(contents=audio_binary)\n",
    "    except :\n",
    "        return None\n",
    "    # Since all the data is single channel (mono), drop the `channels`\n",
    "    # axis from the array.\n",
    "    return tf.squeeze(audio, axis=-1)\n",
    "\n",
    "def get_spectrogram(waveform):\n",
    "    # Zero-padding for an audio waveform with less than 16,000 samples.\n",
    "    input_len = 16000\n",
    "    waveform = waveform[:input_len]\n",
    "    zero_padding = tf.zeros(\n",
    "        [16000] - tf.shape(waveform),\n",
    "        dtype=tf.float32)\n",
    "    # Cast the waveform tensors' dtype to float32.\n",
    "    waveform = tf.cast(waveform, dtype=tf.float32)\n",
    "    # Concatenate the waveform with `zero_padding`, which ensures all audio\n",
    "    # clips are of the same length.\n",
    "    equal_length = tf.concat([waveform, zero_padding], 0)\n",
    "    # Convert the waveform to a spectrogram via a STFT.\n",
    "    spectrogram = tf.signal.stft(\n",
    "        equal_length, frame_length=255, frame_step=128)\n",
    "    # Obtain the magnitude of the STFT.\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    # Add a `channels` dimension, so that the spectrogram can be used\n",
    "    # as image-like input data with convolution layers (which expect\n",
    "    # shape (`batch_size`, `height`, `width`, `channels`).\n",
    "    spectrogram = spectrogram[..., tf.newaxis]\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMANDS = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\", \"_background_noise_\"]\n",
    "TARGETS = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\", \"unknown\"]\n",
    "map_class_to_id = {'yes':0, 'no':1, 'up':2, 'down':3, 'left':4, 'right':5, 'on':6, 'off':7, 'stop':8, 'go':9, 'unknown':10, '_background_noise_':11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"full_df.csv\"\n",
    "DATA_PATH = \"/home/lagarrueal/voice_commands/data/\"\n",
    "\n",
    "dataset = pd.read_csv('../dataframes/full_df.csv')\n",
    "test_ds = dataset[dataset['set'] == 'testing']\n",
    "test_ds = test_ds.reset_index(drop = True)\n",
    "\n",
    "test_ds['waveform'] = test_ds.apply(lambda row: decode_audio(tf.io.read_file(DATA_PATH + row['label'] + \"/\" + row['filename'])), axis=1)\n",
    "test_ds = test_ds.dropna()\n",
    "test_ds = test_ds.reset_index(drop = True)\n",
    "test_ds['spectrogram'] = test_ds['waveform'].apply(lambda x: get_spectrogram(x))\n",
    "test_ds['label'] = test_ds['label'].apply(lambda x: x if x in COMMANDS else \"unknown\")\n",
    "test_ds['label'] = test_ds['label'].apply(lambda x: map_class_to_id[x])\n",
    "\n",
    "del dataset\n",
    "\n",
    "test_audio = []\n",
    "test_labels = []\n",
    "\n",
    "for audio, label in zip(test_ds['spectrogram'], test_ds['label']):\n",
    "    test_audio.append(tf.convert_to_tensor(audio, dtype=tf.float32))\n",
    "    test_labels.append(label)\n",
    "\n",
    "model = tf.keras.models.load_model('model_cnn.h5')\n",
    "\n",
    "test_audio = np.array([x.numpy() for x in test_audio])\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "y_pred = np.argmax(model.predict(test_audio), axis=1)\n",
    "y_true = test_labels\n",
    "\n",
    "mat_conf = tf.math.confusion_matrix(y_true, y_pred, num_classes=11)\n",
    "# Normalise\n",
    "mat_conf_normalized = mat_conf.astype('float') / mat_conf.sum(axis=1)[:, np.newaxis]\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(mat_conf, annot=True, fmt='.2f', xticklabels=TARGETS, yticklabels=TARGETS)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.savefig('matconf_normalized.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".VC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb90f69ab11f7b64879b3541618ed33a901b87f3086df14cf2a5b640eb9a4696"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
