{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cytech/deep-learning/voice_commands/VoiceCommands/.VC/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-02-08 16:17:37.027613: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-08 16:17:37.459494: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-08 16:17:37.459528: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-08 16:17:38.481695: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-08 16:17:38.482059: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-08 16:17:38.482080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import HubertForSequenceClassification, Wav2Vec2FeatureExtractor\n",
    "from torchaudio.sox_effects import apply_effects_file\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "effects = [[\"channels\", \"1\"], [\"rate\", \"16000\"], [\"gain\", \"-3.0\"]]\n",
    "def map_to_array(example):\n",
    "    speech, _ = apply_effects_file(example[\"file\"], effects)\n",
    "    example[\"speech\"] = speech.squeeze(0).numpy()\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset superb_demo (/home/cytech/.cache/huggingface/datasets/anton-l___superb_demo/ks/1.9.0/77d23894ff429329a7fe80f9007cabb0deec321316f8dda1a1e9d10ffa089d08)\n"
     ]
    }
   ],
   "source": [
    "# load a demo dataset and read audio files\n",
    "# dataset = load_dataset(\"anton-l/superb_demo\", \"ks\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['file', 'audio', 'label'],\n",
       "    num_rows: 8\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/cytech/.cache/huggingface/datasets/anton-l___superb_demo/ks/1.9.0/77d23894ff429329a7fe80f9007cabb0deec321316f8dda1a1e9d10ffa089d08/cache-817152a508c5ceb5.arrow\n"
     ]
    }
   ],
   "source": [
    "# dataset = dataset.map(map_to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = HubertForSequenceClassification.from_pretrained(\"superb/hubert-large-superb-ks\")\n",
    "# feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"superb/hubert-large-superb-ks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['file', 'audio', 'label', 'speech'],\n",
       "    num_rows: 8\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compute attention masks and normalize the waveform if needed\n",
    "# inputs = feature_extractor(dataset[:4][\"speech\"], sampling_rate=16000, padding=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits = model(**inputs).logits\n",
    "# predicted_ids = torch.argmax(logits, dim=-1)\n",
    "# labels = [model.config.id2label[_id] for _id in predicted_ids.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### IMPLEMENT TRANSFER LEARNING HERE ###\n",
    "# ### Keep the same model architecture and only change the weights of the last layer ###\n",
    "# ### Retrain the last layer with our own dataset ###\n",
    "\n",
    "# model.save_pretrained(\"../models/hubert_large_superb_ks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 17:02:06.830058: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-08 17:02:07.514990: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-08 17:02:07.515086: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-08 17:02:09.533240: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-08 17:02:09.533435: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-08 17:02:09.533447: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import HubertForSequenceClassification, Wav2Vec2FeatureExtractor\n",
    "from torchaudio.sox_effects import apply_effects_file\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 17:02:12.662167: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-08 17:02:12.662534: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-08 17:02:12.662819: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Student-laptop): /proc/driver/nvidia/version does not exist\n",
      "2023-02-08 17:02:12.664853: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "DATA_PATH = '../data/'\n",
    "COMMANDS = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\", \"_background_noise_\"]\n",
    "TARGETS = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\", \"unknown\", \"_background_noise_\"]\n",
    "map_class_to_id = {'yes':0, 'no':1, 'up':2, 'down':3, 'left':4, 'right':5, 'on':6, 'off':7, 'stop':8, 'go':9, 'unknown':10, '_background_noise_':11}\n",
    "\n",
    "def decode_audio(audio_binary):\n",
    "    # Decode WAV-encoded audio files to `float32` tensors, \n",
    "    # normalized to the [-1.0, 1.0] range. Return `float32` audio and a sample rate.\n",
    "    try :\n",
    "        audio, _ = tf.audio.decode_wav(contents=audio_binary)\n",
    "    except :\n",
    "        return None\n",
    "    # Since all the data is single channel (mono), drop the `channels`\n",
    "    # axis from the array.\n",
    "    return tf.squeeze(audio, axis=-1)\n",
    "\n",
    "\n",
    "dataset = pd.read_csv(\"../dataframes_under_sampled/dataset_unsa.csv\")\n",
    "dataset = dataset.head(20)\n",
    "dataset['waveform'] = dataset.apply(lambda row: decode_audio(tf.io.read_file(DATA_PATH + row['label'] + \"/\" + row['filename'])), axis=1)\n",
    "dataset['label'] = dataset['label'].apply(lambda x: x if x in COMMANDS else \"unknown\")\n",
    "# dataset['label'] = dataset['label'].apply(lambda x: map_class_to_id[x])\n",
    "dataset = dataset.rename(columns={'label': 'labels'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>labels</th>\n",
       "      <th>set</th>\n",
       "      <th>waveform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4e6902d0_nohash_1.wav</td>\n",
       "      <td>unknown</td>\n",
       "      <td>validation</td>\n",
       "      <td>(tf.Tensor(3.0517578e-05, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a1533da4_nohash_2.wav</td>\n",
       "      <td>unknown</td>\n",
       "      <td>testing</td>\n",
       "      <td>(tf.Tensor(0.00018310547, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113b3fbc_nohash_3.wav</td>\n",
       "      <td>on</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(0.0012207031, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cc3b5b62_nohash_3.wav</td>\n",
       "      <td>left</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(-6.1035156e-05, shape=(), dtype=flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96d8bb6f_nohash_0.wav</td>\n",
       "      <td>unknown</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(-0.00033569336, shape=(), dtype=flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>964e8cfd_nohash_0.wav</td>\n",
       "      <td>unknown</td>\n",
       "      <td>testing</td>\n",
       "      <td>(tf.Tensor(0.00018310547, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6f2f57c1_nohash_0.wav</td>\n",
       "      <td>unknown</td>\n",
       "      <td>testing</td>\n",
       "      <td>(tf.Tensor(-0.00021362305, shape=(), dtype=flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>789e4ee7_nohash_0.wav</td>\n",
       "      <td>unknown</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(-0.000579834, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>f618568f_nohash_0.wav</td>\n",
       "      <td>unknown</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(0.0009765625, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1851e33b_nohash_0.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(-0.002319336, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1b42b551_nohash_4.wav</td>\n",
       "      <td>unknown</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(0.00064086914, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2cf28b70_nohash_1.wav</td>\n",
       "      <td>unknown</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(-0.0010681152, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>97f4c236_nohash_4.wav</td>\n",
       "      <td>up</td>\n",
       "      <td>testing</td>\n",
       "      <td>(tf.Tensor(0.0012207031, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>c351e611_nohash_1.wav</td>\n",
       "      <td>unknown</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(-0.0021362305, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1e31353f_nohash_0.wav</td>\n",
       "      <td>unknown</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(0.0019226074, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>72e382bd_nohash_2.wav</td>\n",
       "      <td>down</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(0.0007324219, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>b5cf6ea8_nohash_9.wav</td>\n",
       "      <td>unknown</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(3.0517578e-05, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>e98cb283_nohash_0.wav</td>\n",
       "      <td>unknown</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(0.08291626, shape=(), dtype=float32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>97f4c236_nohash_0.wav</td>\n",
       "      <td>unknown</td>\n",
       "      <td>testing</td>\n",
       "      <td>(tf.Tensor(-0.00039672852, shape=(), dtype=flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>682e1687_nohash_0.wav</td>\n",
       "      <td>go</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(0.0022888184, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 filename   labels         set  \\\n",
       "0   4e6902d0_nohash_1.wav  unknown  validation   \n",
       "1   a1533da4_nohash_2.wav  unknown     testing   \n",
       "2   113b3fbc_nohash_3.wav       on    training   \n",
       "3   cc3b5b62_nohash_3.wav     left    training   \n",
       "4   96d8bb6f_nohash_0.wav  unknown    training   \n",
       "5   964e8cfd_nohash_0.wav  unknown     testing   \n",
       "6   6f2f57c1_nohash_0.wav  unknown     testing   \n",
       "7   789e4ee7_nohash_0.wav  unknown    training   \n",
       "8   f618568f_nohash_0.wav  unknown    training   \n",
       "9   1851e33b_nohash_0.wav    right    training   \n",
       "10  1b42b551_nohash_4.wav  unknown    training   \n",
       "11  2cf28b70_nohash_1.wav  unknown    training   \n",
       "12  97f4c236_nohash_4.wav       up     testing   \n",
       "13  c351e611_nohash_1.wav  unknown    training   \n",
       "14  1e31353f_nohash_0.wav  unknown    training   \n",
       "15  72e382bd_nohash_2.wav     down    training   \n",
       "16  b5cf6ea8_nohash_9.wav  unknown    training   \n",
       "17  e98cb283_nohash_0.wav  unknown    training   \n",
       "18  97f4c236_nohash_0.wav  unknown     testing   \n",
       "19  682e1687_nohash_0.wav       go    training   \n",
       "\n",
       "                                             waveform  \n",
       "0   (tf.Tensor(3.0517578e-05, shape=(), dtype=floa...  \n",
       "1   (tf.Tensor(0.00018310547, shape=(), dtype=floa...  \n",
       "2   (tf.Tensor(0.0012207031, shape=(), dtype=float...  \n",
       "3   (tf.Tensor(-6.1035156e-05, shape=(), dtype=flo...  \n",
       "4   (tf.Tensor(-0.00033569336, shape=(), dtype=flo...  \n",
       "5   (tf.Tensor(0.00018310547, shape=(), dtype=floa...  \n",
       "6   (tf.Tensor(-0.00021362305, shape=(), dtype=flo...  \n",
       "7   (tf.Tensor(-0.000579834, shape=(), dtype=float...  \n",
       "8   (tf.Tensor(0.0009765625, shape=(), dtype=float...  \n",
       "9   (tf.Tensor(-0.002319336, shape=(), dtype=float...  \n",
       "10  (tf.Tensor(0.00064086914, shape=(), dtype=floa...  \n",
       "11  (tf.Tensor(-0.0010681152, shape=(), dtype=floa...  \n",
       "12  (tf.Tensor(0.0012207031, shape=(), dtype=float...  \n",
       "13  (tf.Tensor(-0.0021362305, shape=(), dtype=floa...  \n",
       "14  (tf.Tensor(0.0019226074, shape=(), dtype=float...  \n",
       "15  (tf.Tensor(0.0007324219, shape=(), dtype=float...  \n",
       "16  (tf.Tensor(3.0517578e-05, shape=(), dtype=floa...  \n",
       "17  (tf.Tensor(0.08291626, shape=(), dtype=float32...  \n",
       "18  (tf.Tensor(-0.00039672852, shape=(), dtype=flo...  \n",
       "19  (tf.Tensor(0.0022888184, shape=(), dtype=float...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns=['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>set</th>\n",
       "      <th>waveform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unknown</td>\n",
       "      <td>validation</td>\n",
       "      <td>(tf.Tensor(3.0517578e-05, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unknown</td>\n",
       "      <td>testing</td>\n",
       "      <td>(tf.Tensor(0.00018310547, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>on</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(0.0012207031, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>left</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(-6.1035156e-05, shape=(), dtype=flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unknown</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(-0.00033569336, shape=(), dtype=flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>unknown</td>\n",
       "      <td>testing</td>\n",
       "      <td>(tf.Tensor(0.00018310547, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>unknown</td>\n",
       "      <td>testing</td>\n",
       "      <td>(tf.Tensor(-0.00021362305, shape=(), dtype=flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>unknown</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(-0.000579834, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>unknown</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(0.0009765625, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>right</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(-0.002319336, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>unknown</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(0.00064086914, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>unknown</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(-0.0010681152, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>up</td>\n",
       "      <td>testing</td>\n",
       "      <td>(tf.Tensor(0.0012207031, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>unknown</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(-0.0021362305, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>unknown</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(0.0019226074, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>down</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(0.0007324219, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>unknown</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(3.0517578e-05, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>unknown</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(0.08291626, shape=(), dtype=float32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>unknown</td>\n",
       "      <td>testing</td>\n",
       "      <td>(tf.Tensor(-0.00039672852, shape=(), dtype=flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>go</td>\n",
       "      <td>training</td>\n",
       "      <td>(tf.Tensor(0.0022888184, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     labels         set                                           waveform\n",
       "0   unknown  validation  (tf.Tensor(3.0517578e-05, shape=(), dtype=floa...\n",
       "1   unknown     testing  (tf.Tensor(0.00018310547, shape=(), dtype=floa...\n",
       "2        on    training  (tf.Tensor(0.0012207031, shape=(), dtype=float...\n",
       "3      left    training  (tf.Tensor(-6.1035156e-05, shape=(), dtype=flo...\n",
       "4   unknown    training  (tf.Tensor(-0.00033569336, shape=(), dtype=flo...\n",
       "5   unknown     testing  (tf.Tensor(0.00018310547, shape=(), dtype=floa...\n",
       "6   unknown     testing  (tf.Tensor(-0.00021362305, shape=(), dtype=flo...\n",
       "7   unknown    training  (tf.Tensor(-0.000579834, shape=(), dtype=float...\n",
       "8   unknown    training  (tf.Tensor(0.0009765625, shape=(), dtype=float...\n",
       "9     right    training  (tf.Tensor(-0.002319336, shape=(), dtype=float...\n",
       "10  unknown    training  (tf.Tensor(0.00064086914, shape=(), dtype=floa...\n",
       "11  unknown    training  (tf.Tensor(-0.0010681152, shape=(), dtype=floa...\n",
       "12       up     testing  (tf.Tensor(0.0012207031, shape=(), dtype=float...\n",
       "13  unknown    training  (tf.Tensor(-0.0021362305, shape=(), dtype=floa...\n",
       "14  unknown    training  (tf.Tensor(0.0019226074, shape=(), dtype=float...\n",
       "15     down    training  (tf.Tensor(0.0007324219, shape=(), dtype=float...\n",
       "16  unknown    training  (tf.Tensor(3.0517578e-05, shape=(), dtype=floa...\n",
       "17  unknown    training  (tf.Tensor(0.08291626, shape=(), dtype=float32...\n",
       "18  unknown     testing  (tf.Tensor(-0.00039672852, shape=(), dtype=flo...\n",
       "19       go    training  (tf.Tensor(0.0022888184, shape=(), dtype=float..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[dataset['set'] == 'training'].drop(columns=['set']).reset_index(drop=True)\n",
    "eval_dataset = dataset[dataset['set'] == 'testing'].drop(columns=['set']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HubertForSequenceClassification.from_pretrained(\"superb/hubert-large-superb-ks\")\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"superb/hubert-large-superb-ks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>waveform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>on</td>\n",
       "      <td>(tf.Tensor(0.0012207031, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>left</td>\n",
       "      <td>(tf.Tensor(-6.1035156e-05, shape=(), dtype=flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unknown</td>\n",
       "      <td>(tf.Tensor(-0.00033569336, shape=(), dtype=flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unknown</td>\n",
       "      <td>(tf.Tensor(-0.000579834, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unknown</td>\n",
       "      <td>(tf.Tensor(0.0009765625, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>right</td>\n",
       "      <td>(tf.Tensor(-0.002319336, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>unknown</td>\n",
       "      <td>(tf.Tensor(0.00064086914, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>unknown</td>\n",
       "      <td>(tf.Tensor(-0.0010681152, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>unknown</td>\n",
       "      <td>(tf.Tensor(-0.0021362305, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>unknown</td>\n",
       "      <td>(tf.Tensor(0.0019226074, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>down</td>\n",
       "      <td>(tf.Tensor(0.0007324219, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>unknown</td>\n",
       "      <td>(tf.Tensor(3.0517578e-05, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>unknown</td>\n",
       "      <td>(tf.Tensor(0.08291626, shape=(), dtype=float32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>go</td>\n",
       "      <td>(tf.Tensor(0.0022888184, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     labels                                           waveform\n",
       "0        on  (tf.Tensor(0.0012207031, shape=(), dtype=float...\n",
       "1      left  (tf.Tensor(-6.1035156e-05, shape=(), dtype=flo...\n",
       "2   unknown  (tf.Tensor(-0.00033569336, shape=(), dtype=flo...\n",
       "3   unknown  (tf.Tensor(-0.000579834, shape=(), dtype=float...\n",
       "4   unknown  (tf.Tensor(0.0009765625, shape=(), dtype=float...\n",
       "5     right  (tf.Tensor(-0.002319336, shape=(), dtype=float...\n",
       "6   unknown  (tf.Tensor(0.00064086914, shape=(), dtype=floa...\n",
       "7   unknown  (tf.Tensor(-0.0010681152, shape=(), dtype=floa...\n",
       "8   unknown  (tf.Tensor(-0.0021362305, shape=(), dtype=floa...\n",
       "9   unknown  (tf.Tensor(0.0019226074, shape=(), dtype=float...\n",
       "10     down  (tf.Tensor(0.0007324219, shape=(), dtype=float...\n",
       "11  unknown  (tf.Tensor(3.0517578e-05, shape=(), dtype=floa...\n",
       "12  unknown  (tf.Tensor(0.08291626, shape=(), dtype=float32...\n",
       "13       go  (tf.Tensor(0.0022888184, shape=(), dtype=float..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "12",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/deep-learning/voice_commands/VoiceCommands/.VC/lib/python3.8/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/deep-learning/voice_commands/VoiceCommands/.VC/lib/python3.8/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/deep-learning/voice_commands/VoiceCommands/.VC/lib/python3.8/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 12",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 7\u001b[0m         \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_dataloader:\n\u001b[1;32m      8\u001b[0m                 batch \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k,v \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m      9\u001b[0m                 outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbatch)\n",
      "File \u001b[0;32m~/deep-learning/voice_commands/VoiceCommands/.VC/lib/python3.8/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/deep-learning/voice_commands/VoiceCommands/.VC/lib/python3.8/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/deep-learning/voice_commands/VoiceCommands/.VC/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/deep-learning/voice_commands/VoiceCommands/.VC/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/deep-learning/voice_commands/VoiceCommands/.VC/lib/python3.8/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/deep-learning/voice_commands/VoiceCommands/.VC/lib/python3.8/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 12"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "        for batch in train_dataloader:\n",
    "                batch = {k: v for k,v in batch.items()}\n",
    "                outputs = model(**batch)\n",
    "                loss = outputs.loss\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "                progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 4.20k/4.20k [00:00<00:00, 3.62MB/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Evaluation module cache file doesn't exist. Please make sure that you call `add` or `add_batch` at least once before calling `compute`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     predictions \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(logits, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m     metric\u001b[39m.\u001b[39madd_batch(predictions\u001b[39m=\u001b[39mpredictions, references\u001b[39m=\u001b[39mbatch[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m---> 14\u001b[0m metric\u001b[39m.\u001b[39;49mcompute()\n",
      "File \u001b[0;32m~/deep-learning/voice_commands/VoiceCommands/.VC/lib/python3.8/site-packages/evaluate/module.py:433\u001b[0m, in \u001b[0;36mEvaluationModule.compute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(v \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    432\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_batch(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs)\n\u001b[0;32m--> 433\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_finalize()\n\u001b[1;32m    435\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache_file_name \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilelock \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/deep-learning/voice_commands/VoiceCommands/.VC/lib/python3.8/site-packages/evaluate/module.py:385\u001b[0m, in \u001b[0;36mEvaluationModule._finalize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39mfrom_buffer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_writer\u001b[39m.\u001b[39mgetvalue())\n\u001b[1;32m    383\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_id \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    384\u001b[0m     \u001b[39m# Let's acquire a lock on each node files to be sure they are finished writing\u001b[39;00m\n\u001b[0;32m--> 385\u001b[0m     file_paths, filelocks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_all_cache_files()\n\u001b[1;32m    387\u001b[0m     \u001b[39m# Read the predictions and references\u001b[39;00m\n\u001b[1;32m    388\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/deep-learning/voice_commands/VoiceCommands/.VC/lib/python3.8/site-packages/evaluate/module.py:302\u001b[0m, in \u001b[0;36mEvaluationModule._get_all_cache_files\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_process \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache_file_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    303\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mEvaluation module cache file doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt exist. Please make sure that you call `add` or `add_batch` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mat least once before calling `compute`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m         )\n\u001b[1;32m    306\u001b[0m     file_paths \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache_file_name]\n\u001b[1;32m    307\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Evaluation module cache file doesn't exist. Please make sure that you call `add` or `add_batch` at least once before calling `compute`."
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "model.eval()\n",
    "for batch in val_dataloader:\n",
    "    batch = {k: v for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute attention masks and normalize the waveform if needed\n",
    "inputs = feature_extractor(dataset[:4][\"waveform\"], sampling_rate=16000, padding=True, return_tensors=\"pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".VC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb90f69ab11f7b64879b3541618ed33a901b87f3086df14cf2a5b640eb9a4696"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
